{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "corrected-sweden",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-nomination",
   "metadata": {},
   "source": [
    "We begin our analysis with randomm forest classifer. Random forest is the meta estimator which fits number of decision tree classifiers on various subsamples of data and uses averaging for improving the model accuracy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "explicit-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required packages\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "from fairlearn.metrics import MetricFrame\n",
    "from fairlearn.reductions import GridSearch, EqualizedOdds, TruePositiveRateParity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-character",
   "metadata": {},
   "source": [
    "## Modelling Company Employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "short-symposium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into dataframe\n",
    "df = pd.read_csv('./../../../datasets/preprocessed_ce.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-variable",
   "metadata": {},
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "raised-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_col = 'have you ever sought treatment for a mental health disorder from a mental health professional?'\n",
    "y = df[tgt_col]\n",
    "X = df.drop(tgt_col, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-mentor",
   "metadata": {},
   "source": [
    "Let's check if the data is imbalanced or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "incoming-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into trainining and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "developmental-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep copy of original variables\n",
    "X_train_ori = X_train.copy()\n",
    "X_test_ori = X_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-traveler",
   "metadata": {},
   "source": [
    "### Categorical features encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-bristol",
   "metadata": {},
   "source": [
    "Before we move forward to encode categorical features, it is necessary to identify them first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "graduate-country",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1225 entries, 0 to 1224\n",
      "Data columns (total 55 columns):\n",
      " #   Column                                                                                                                                                                                                                          Non-Null Count  Dtype  \n",
      "---  ------                                                                                                                                                                                                                          --------------  -----  \n",
      " 0   are you self-employed?                                                                                                                                                                                                          1225 non-null   int64  \n",
      " 1   how many employees does your company or organization have?                                                                                                                                                                      1225 non-null   object \n",
      " 2   is your employer primarily a tech company/organization?                                                                                                                                                                         1225 non-null   float64\n",
      " 3   is your primary role within your company related to tech/it?                                                                                                                                                                    1225 non-null   float64\n",
      " 4   does your employer provide mental health benefits as part of healthcare coverage?                                                                                                                                               1225 non-null   object \n",
      " 5   do you know the options for mental health care available under your employer-provided health coverage?                                                                                                                          1225 non-null   object \n",
      " 6   has your employer ever formally discussed mental health (for example, as part of a wellness campaign or other official communication)?                                                                                          1225 non-null   object \n",
      " 7   does your employer offer resources to learn more about mental health disorders and options for seeking help?                                                                                                                    1225 non-null   object \n",
      " 8   is your anonymity protected if you choose to take advantage of mental health or substance abuse treatment resources provided by your employer?                                                                                  1225 non-null   object \n",
      " 9   if a mental health issue prompted you to request a medical leave from work, how easy or difficult would it be to ask for that leave?                                                                                            1225 non-null   object \n",
      " 10  would you feel more comfortable talking to your coworkers about your physical health or your mental health?                                                                                                                     1225 non-null   object \n",
      " 11  would you feel comfortable discussing a mental health issue with your direct supervisor(s)?                                                                                                                                     1225 non-null   object \n",
      " 12  have you ever discussed your mental health with your employer?                                                                                                                                                                  1225 non-null   float64\n",
      " 13  would you feel comfortable discussing a mental health issue with your coworkers?                                                                                                                                                1225 non-null   object \n",
      " 14  have you ever discussed your mental health with coworkers?                                                                                                                                                                      1225 non-null   float64\n",
      " 15  have you ever had a coworker discuss their or another coworker's mental health with you?                                                                                                                                        1225 non-null   float64\n",
      " 16  overall, how much importance does your employer place on physical health?                                                                                                                                                       1225 non-null   float64\n",
      " 17  overall, how much importance does your employer place on mental health?                                                                                                                                                         1225 non-null   float64\n",
      " 18  do you have previous employers?                                                                                                                                                                                                 1225 non-null   int64  \n",
      " 19  was your employer primarily a tech company/organization?                                                                                                                                                                        1225 non-null   float64\n",
      " 20  have your previous employers provided mental health benefits?                                                                                                                                                                   1225 non-null   object \n",
      " 21  were you aware of the options for mental health care provided by your previous employers?                                                                                                                                       1225 non-null   object \n",
      " 22  did your previous employers ever formally discuss mental health (as part of a wellness campaign or other official communication)?                                                                                               1225 non-null   object \n",
      " 23  did your previous employers provide resources to learn more about mental health disorders and how to seek help?                                                                                                                 1225 non-null   object \n",
      " 24  was your anonymity protected if you chose to take advantage of mental health or substance abuse treatment resources with previous employers?                                                                                    1225 non-null   object \n",
      " 25  would you have felt more comfortable talking to your previous employer about your physical health or your mental health?                                                                                                        1225 non-null   object \n",
      " 26  would you have been willing to discuss your mental health with your direct supervisor(s)?                                                                                                                                       1225 non-null   object \n",
      " 27  did you ever discuss your mental health with your previous employer?                                                                                                                                                            1225 non-null   float64\n",
      " 28  would you have been willing to discuss your mental health with your coworkers at previous employers?                                                                                                                            1225 non-null   object \n",
      " 29  did you ever discuss your mental health with a previous coworker(s)?                                                                                                                                                            1225 non-null   float64\n",
      " 30  did you ever have a previous coworker discuss their or another coworker's mental health with you?                                                                                                                               1225 non-null   float64\n",
      " 31  overall, how much importance did your previous employer place on physical health?                                                                                                                                               1225 non-null   float64\n",
      " 32  overall, how much importance did your previous employer place on mental health?                                                                                                                                                 1225 non-null   float64\n",
      " 33  do you currently have a mental health disorder?                                                                                                                                                                                 1225 non-null   object \n",
      " 34  have you had a mental health disorder in the past?                                                                                                                                                                              1225 non-null   object \n",
      " 35  have you ever sought treatment for a mental health disorder from a mental health professional?                                                                                                                                  1225 non-null   int64  \n",
      " 36  do you have a family history of mental illness?                                                                                                                                                                                 1225 non-null   object \n",
      " 37  if you have a mental health disorder, how often do you feel that it interferes with your work when being treated effectively?                                                                                                   1225 non-null   object \n",
      " 38  if you have a mental health disorder, how often do you feel that it interferes with your work when not being treated effectively (i.e., when you are experiencing symptoms)?                                                    1225 non-null   object \n",
      " 39  have your observations of how another individual who discussed a mental health issue made you less likely to reveal a mental health issue yourself in your current workplace?                                                   1225 non-null   object \n",
      " 40  how willing would you be to share with friends and family that you have a mental illness?                                                                                                                                       1225 non-null   int64  \n",
      " 41  would you be willing to bring up a physical health issue with a potential employer in an interview?                                                                                                                             1225 non-null   object \n",
      " 42  would you bring up your mental health with a potential employer in an interview?                                                                                                                                                1225 non-null   object \n",
      " 43  are you openly identified at work as a person with a mental health issue?                                                                                                                                                       1225 non-null   float64\n",
      " 44  if they knew you suffered from a mental health disorder, how do you think that team members/co-workers would react?                                                                                                             1225 non-null   float64\n",
      " 45  have you observed or experienced an unsupportive or badly handled response to a mental health issue in your current or previous workplace?                                                                                      1225 non-null   object \n",
      " 46  have you observed or experienced supportive or well handled response to a mental health issue in your current or previous workplace?                                                                                            1225 non-null   object \n",
      " 47  overall, how well do you think the tech industry supports employees with mental health issues?                                                                                                                                  1225 non-null   float64\n",
      " 48  would you be willing to talk to one of us more extensively about your experiences with mental health issues in the tech industry? (note that all interview responses would be used anonymously and only with your permission.)  1225 non-null   float64\n",
      " 49  what is your age?                                                                                                                                                                                                               1225 non-null   float64\n",
      " 50  what is your gender?                                                                                                                                                                                                            1225 non-null   object \n",
      " 51  what country do you live in?                                                                                                                                                                                                    1225 non-null   object \n",
      " 52  what is your race?                                                                                                                                                                                                              1225 non-null   object \n",
      " 53  what country do you work in?                                                                                                                                                                                                    1225 non-null   object \n",
      " 54  year                                                                                                                                                                                                                            1225 non-null   int64  \n",
      "dtypes: float64(18), int64(5), object(32)\n",
      "memory usage: 526.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-america",
   "metadata": {},
   "source": [
    "Looking at the information of dataframe, there are quite a lot of fetuares which has data type as \"object\". It is not necessary that all the features with data type as \"object\" be categorical features. There may be certain columns which might binary values which can be represented by booleans. It is better to check column one by one.  \n",
    "But for now, I would like to go with the assumption that all the columns with data type as \"object\" are categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "duplicate-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = df.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-swing",
   "metadata": {},
   "source": [
    "There are 32 columns out of 55 which are categorical in nature. Out of those, after examining the data manually, we can infer that one of them is ordinal in nature and others can be treated as nominal columns. The column - \"how many employees does your company or organization have?\" - which gives information regarding the size of the company can be treated as ordinal coulmn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "recreational-expense",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-d59b31438a42>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['how many employees does your company or organization have?'] = X_train['how many employees does your company or organization have?'].replace({'1-5':1,\n",
      "<ipython-input-8-d59b31438a42>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test['how many employees does your company or organization have?'] = X_test['how many employees does your company or organization have?'].replace({'1-5':1,\n"
     ]
    }
   ],
   "source": [
    "# Encoding ordinal column for training data\n",
    "X_train['how many employees does your company or organization have?'] = X_train['how many employees does your company or organization have?'].replace({'1-5':1, \n",
    "                                                                                                                                              '6-25':2, \n",
    "                                                                                                                                              '26-100':3, \n",
    "                                                                                                                                              '100-500':4,\n",
    "                                                                                                                                              '500-1000':5,\n",
    "                                                                                                                                              'More than 1000':6})\n",
    "\n",
    "# Encoding ordinal column for testing data\n",
    "X_test['how many employees does your company or organization have?'] = X_test['how many employees does your company or organization have?'].replace({'1-5':1, \n",
    "                                                                                                                                              '6-25':2, \n",
    "                                                                                                                                              '26-100':3, \n",
    "                                                                                                                                              '100-500':4,\n",
    "                                                                                                                                              '500-1000':5,\n",
    "                                                                                                                                              'More than 1000':6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "seventh-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding nominal columns for training data\n",
    "for column in cat_cols:\n",
    "    dummy = pd.get_dummies(X_train[column], prefix=str(column))\n",
    "    X_train = pd.concat([X_train, dummy], axis=1)\n",
    "    X_train.drop(column, axis=1, inplace=True)\n",
    "    \n",
    "# Encoding nominal columns for testing data\n",
    "for column in cat_cols:\n",
    "    dummy = pd.get_dummies(X_test[column], prefix=str(column))\n",
    "    X_test = pd.concat([X_test, dummy], axis=1)\n",
    "    X_test.drop(column, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "stone-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill value 0 for mismatched columns\n",
    "mis_cols = list(set(X_train.columns) - set(X_test.columns))\n",
    "X_test[mis_cols] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-staff",
   "metadata": {},
   "source": [
    "### Imbalance check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "exterior-video",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    779\n",
       "0    446\n",
       "Name: have you ever sought treatment for a mental health disorder from a mental health professional?, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-alcohol",
   "metadata": {},
   "source": [
    "The data is imbalanced. In order to use any of the machine learning algorithm, we need to either over the minority class or downsample the majority. Considering the fact that we have less number of records in the data set, it is better to oversample. But, only training data needs to be oversample.  \n",
    "For oversampling, Sample Minority Oversampling Technique (SMOTE) will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sharing-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample the minority class in the target variable\n",
    "oversample = SMOTE()\n",
    "X_train, y_train = oversample.fit_resample(X_train.values, y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-seven",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "placed-consistency",
   "metadata": {},
   "source": [
    "There are various paramters which random forest algorithm uses to train the model. Our aim is to find those paramters, also known as hyperparamters, which yeilds us the model with the best fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "pending-calgary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare parameters for grid search\n",
    "\n",
    "# Declare the classifer\n",
    "clf = RandomForestClassifier(class_weight=\"balanced\", bootstrap=True, oob_score=True)\n",
    "\n",
    "# Declare the paramter grid for searching\n",
    "param_grid = dict(\n",
    "    n_estimators = [100, 200, 400],\n",
    "    criterion = ['gini', 'entropy'],\n",
    "    max_depth = [10, 20, 40, None],\n",
    "    max_features = ['sqrt', 'log2', None],\n",
    "    max_samples = [0.4, 0.8, None]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "informative-lending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=RandomForestClassifier(class_weight='balanced',\n",
       "                                              oob_score=True),\n",
       "             n_jobs=7,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [10, 20, 40, None],\n",
       "                         'max_features': ['sqrt', 'log2', None],\n",
       "                         'max_samples': [0.4, 0.8, None],\n",
       "                         'n_estimators': [100, 200, 400]},\n",
       "             scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "rf_clf = GridSearchCV(clf, param_grid, scoring='f1', n_jobs=7, cv=5, verbose=2)\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "civilian-ocean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
       "                       max_depth=10, max_features='sqrt', max_samples=0.8,\n",
       "                       oob_score=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "detected-choir",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load the model if required\n",
    "import joblib\n",
    "# joblib.dump(rf_clf.best_estimator_, './../../../models/rf_clf.pkl')\n",
    "rf_clf = joblib.load('./../../../models/rf_clf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "handmade-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict outcomes with test set\n",
    "# y_pred = rf_clf.best_estimator_.predict(X_test)\n",
    "y_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fourth-dietary",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-chancellor",
   "metadata": {},
   "source": [
    "In order to compute sensitivity and specificity, we need values such as true positives, true negatives, false positives and false neagatives. These values can be easily obtained from confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "considered-postcard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get values from confusion metrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "binding-eagle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.8662420382165605 \n",
      "\n",
      "Specificity: 0.8068181818181818 \n",
      "\n",
      "F1 score: 0.8774193548387097 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.81      0.79        88\n",
      "           1       0.89      0.87      0.88       157\n",
      "\n",
      "    accuracy                           0.84       245\n",
      "   macro avg       0.83      0.84      0.83       245\n",
      "weighted avg       0.85      0.84      0.85       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute sensitivity\n",
    "sensitivity = tp/(tp+fn)\n",
    "print(f\"Sensitivity: {sensitivity} \\n\")\n",
    "# Compute specificity\n",
    "specificity = tn/(tn+fp)\n",
    "print(f\"Specificity: {specificity} \\n\")\n",
    "# Compute f1 score \n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1 score: {f1} \\n\")\n",
    "\n",
    "# Compute classicfication report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-violin",
   "metadata": {},
   "source": [
    "From the above report, it can inferred that model is finding it difficult to predict people who need to seek help from mental health professional and that can be acceptable. It won't harm any of us to visit a mental health professional even if we need not seek any help for any mental health issue. On the other hand the model is quite good at telling in case we that much needed help from mental health professional. An average F1 score of 0.83 and the overall F1 score of 0.88 is quite good considering the amount of data that we are training with. Though the model is quite better in predicting the individuals who need help than the ones who do not, the values of specificity and sensitivity are not far apart and hence the overall performance of the model is laudable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-jersey",
   "metadata": {},
   "source": [
    "### Fairness evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-phoenix",
   "metadata": {},
   "source": [
    "There are certain sensitive columns present in the data for which model should be less likely to be biased. Following are the columns for which we will be expecting that model be fair as much as possible:\n",
    "1. Feature revealing gender of the participant ('what is your gender?')\n",
    "2. Feature revealing race of the participant ('what is your race?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-minneapolis",
   "metadata": {},
   "source": [
    "#### Disparity check with respect to gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "approximate-affect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fairness metrics with respect to gender\n",
    "fair_metrics_sex = MetricFrame({'f1': f1_score, 'precision': precision_score, 'recall': recall_score},\n",
    "                          y_test, y_pred, sensitive_features=X_test_ori['what is your gender?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "pending-demonstration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1           0.877419\n",
       "precision    0.888889\n",
       "recall       0.866242\n",
       "dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display overall metrics\n",
    "fair_metrics_sex.overall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-cliff",
   "metadata": {},
   "source": [
    "The overall metrics remains the same as the ungrouped metrics metrics that are calculated above. The overall precision and recall are close enough, indicating that the most of the people selected by the model for seeking help for mental health issues are relevant and also the most of the relevant people are picked by the model. Though obviously, there is huge scope for model improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "institutional-translator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>what is your gender?</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.900901</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.877193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.860215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            f1 precision    recall\n",
       "what is your gender?                              \n",
       "female                0.900901  0.925926  0.877193\n",
       "male                  0.864865  0.869565  0.860215\n",
       "other                 0.857143  0.857143  0.857143"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display metrcis by group\n",
    "fair_metrics_sex.by_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-entry",
   "metadata": {},
   "source": [
    "Model is finding it easier to tag more female candidates who need help than the other counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "hungry-special",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Difference</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.043758</td>\n",
       "      <td>4.375804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.068783</td>\n",
       "      <td>6.878307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.02005</td>\n",
       "      <td>2.005013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Difference Percentage\n",
       "f1          0.043758   4.375804\n",
       "precision   0.068783   6.878307\n",
       "recall       0.02005   2.005013"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_metrics = pd.DataFrame(fair_metrics_sex.difference(method='between_groups'), columns=['Difference'])\n",
    "diff_metrics['Percentage'] = diff_metrics['Difference']*100\n",
    "diff_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-swedish",
   "metadata": {},
   "source": [
    "On a positive note, the difference between the minimum and the maximum metric is not huge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "adapted-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fairness metrics\n",
    "fair_metrics_race = MetricFrame({'f1': f1_score, 'precision': precision_score, 'recall': recall_score},\n",
    "                          y_test, y_pred, sensitive_features=X_test_ori['what is your race?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "engaging-broadcasting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1           0.877419\n",
       "precision    0.888889\n",
       "recall       0.866242\n",
       "dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display overall metrics\n",
    "fair_metrics_race.overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "center-season",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>what is your race?</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black or African American</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I prefer not to answer</th>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>More than one of the above</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.917031</td>\n",
       "      <td>0.929204</td>\n",
       "      <td>0.905172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  f1 precision    recall\n",
       "what is your race?                                      \n",
       "Asian                       0.666667  0.666667  0.666667\n",
       "Black or African American        1.0       1.0       1.0\n",
       "I prefer not to answer      0.764706  0.764706  0.764706\n",
       "More than one of the above       0.8       1.0  0.666667\n",
       "White                       0.917031  0.929204  0.905172"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display metrcis by group\n",
    "fair_metrics_race.by_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-salmon",
   "metadata": {},
   "source": [
    "The model is working perfectly for black or African Americans but working the worst for asian participants. Moreover, for people belongs to more than one race, people selected by the model for help are all relevant but it could not identify all the those who are relevant. For white participants, model is working quite good and the disparity differences with the highest expected value is quite less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "gross-circle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Difference</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Difference Percentage\n",
       "f1          0.333333  33.333333\n",
       "precision   0.333333  33.333333\n",
       "recall      0.333333  33.333333"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_metrics = pd.DataFrame(fair_metrics_race.difference(method='between_groups'), columns=['Difference'])\n",
    "diff_metrics['Percentage'] = diff_metrics['Difference']*100\n",
    "diff_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-manchester",
   "metadata": {},
   "source": [
    "The disparity between the scores are huge and it should be mitigated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-allen",
   "metadata": {},
   "source": [
    "### Mitigated Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confirmed-wheat",
   "metadata": {},
   "source": [
    "Here we will be utilizing the best estimator that we trained using grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "cardiac-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare paramters for mitigated model training\n",
    "best_estimator = RandomForestClassifier(class_weight='balanced', criterion='entropy', \n",
    "                                        max_depth=10, max_features='sqrt', \n",
    "                                        max_samples=0.8,oob_score=True, bootstrap=True)\n",
    "\n",
    "constraint = TruePositiveRateParity(difference_bound=0.005)\n",
    "\n",
    "X_train_rc = pd.DataFrame(X_train, columns=X_test.columns)\n",
    "sensitive_features_columns = [column for index, column in enumerate(X_test.columns) if ('what is your gender?' in column) or ('what is your race?' in column)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "reported-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sf = X_train_rc[sensitive_features_columns]\n",
    "X_train_rc.drop(sensitive_features, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "jewish-haven",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "mitigator = GridSearch(best_estimator, constraint, grid_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "royal-finnish",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/logging/__init__.py\", line 1081, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/logging/__init__.py\", line 925, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/logging/__init__.py\", line 664, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/logging/__init__.py\", line 369, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n",
      "    self.ctx_run(self.run)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 358, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 536, in execute_request\n",
      "    self.do_execute(\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2866, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3071, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-212-a786ba150a1e>\", line 1, in <module>\n",
      "    mitigator.fit(X_train_rc, y_train, sensitive_features=X_train_sf)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/fairlearn/reductions/_grid_search/grid_search.py\", line 142, in fit\n",
      "    grid = _GridGenerator(self.grid_size,\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/fairlearn/reductions/_grid_search/_grid_generator.py\", line 61, in __init__\n",
      "    logger.warning(GRID_DIMENSION_WARN_TEMPLATE, true_dim, GRID_DIMENSION_WARN_THRESHOLD)\n",
      "Message: 'The grid has {} dimensions. It is not recommended to use more than {}, otherwise a prohibitively large grid size is required to explore the space thoroughly. For such cases consider using ExponentiatedGradient from the fairlearn.reductions module.'\n",
      "Arguments: (231, 4)\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/logging/__init__.py\", line 1081, in emit\n",
      "    msg = self.format(record)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/logging/__init__.py\", line 925, in format\n",
      "    return fmt.format(record)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/logging/__init__.py\", line 664, in format\n",
      "    record.message = record.getMessage()\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/logging/__init__.py\", line 369, in getMessage\n",
      "    msg = msg % self.args\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/traitlets/config/application.py\", line 845, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 612, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/asyncio/events.py\", line 81, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/tornado/ioloop.py\", line 688, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/tornado/ioloop.py\", line 741, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/tornado/gen.py\", line 814, in inner\n",
      "    self.ctx_run(self.run)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/tornado/gen.py\", line 775, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 358, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 536, in execute_request\n",
      "    self.do_execute(\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/tornado/gen.py\", line 234, in wrapper\n",
      "    yielded = ctx_run(next, result)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2866, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3071, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-212-a786ba150a1e>\", line 1, in <module>\n",
      "    mitigator.fit(X_train_rc, y_train, sensitive_features=X_train_sf)\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/fairlearn/reductions/_grid_search/grid_search.py\", line 142, in fit\n",
      "    grid = _GridGenerator(self.grid_size,\n",
      "  File \"/Users/pushkar/miniconda3/envs/mh/lib/python3.8/site-packages/fairlearn/reductions/_grid_search/_grid_generator.py\", line 65, in __init__\n",
      "    logger.warning(GRID_SIZE_WARN_TEMPLATE, grid_size, recommended_min_grid_size)\n",
      "Message: 'Generating a grid with {} grid points. It is recommended to use at least {} grid points. Please consider increasing grid_size.'\n",
      "Arguments: (100, 3450873173395281893717377931138512726225554486085193277581262111899648)\n"
     ]
    }
   ],
   "source": [
    "mitigator.fit(X_train_rc, y_train, sensitive_features=X_train_sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "excited-construction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and load the model if required\n",
    "# import joblib\n",
    "# joblib.dump(mitigator, './../../../models/mitigated_rf_clf.pkl')\n",
    "# mitigated_rf = joblib.load('./../../../models/mitigated_rf_clf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "honest-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_rc = X_test.drop(sensitive_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "active-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mitigated = mitigator.predict(X_test_rc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-aruba",
   "metadata": {},
   "source": [
    "### Mitigated Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "moving-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get values from confusion metrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred_mitigated).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "sixth-format",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.8535031847133758 \n",
      "\n",
      "Specificity: 0.8068181818181818 \n",
      "\n",
      "F1 score: 0.8774193548387097 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.81      0.78        88\n",
      "           1       0.89      0.85      0.87       157\n",
      "\n",
      "    accuracy                           0.84       245\n",
      "   macro avg       0.82      0.83      0.83       245\n",
      "weighted avg       0.84      0.84      0.84       245\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute sensitivity\n",
    "sensitivity = tp/(tp+fn)\n",
    "print(f\"Sensitivity: {sensitivity} \\n\")\n",
    "# Compute specificity\n",
    "specificity = tn/(tn+fp)\n",
    "print(f\"Specificity: {specificity} \\n\")\n",
    "# Compute f1 score \n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1 score: {f1} \\n\")\n",
    "\n",
    "# Compute classicfication report\n",
    "print(classification_report(y_test, y_pred_mitigated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "handed-liberia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fairness metrics with respect to gender\n",
    "fair_metrics_sex = MetricFrame({'f1': f1_score, 'precision': precision_score, 'recall': recall_score},\n",
    "                          y_test, y_pred_mitigated, sensitive_features=X_test_ori['what is your gender?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "happy-lightweight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1            0.87013\n",
       "precision    0.887417\n",
       "recall       0.853503\n",
       "dtype: object"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display overall metrics\n",
    "fair_metrics_sex.overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "representative-richmond",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>what is your gender?</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>0.899083</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.859649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>0.854054</td>\n",
       "      <td>0.858696</td>\n",
       "      <td>0.849462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            f1 precision    recall\n",
       "what is your gender?                              \n",
       "female                0.899083  0.942308  0.859649\n",
       "male                  0.854054  0.858696  0.849462\n",
       "other                 0.857143  0.857143  0.857143"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display metrcis by group\n",
    "fair_metrics_sex.by_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "noble-greensboro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Difference</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.045029</td>\n",
       "      <td>4.502851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.085165</td>\n",
       "      <td>8.516484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.010187</td>\n",
       "      <td>1.018676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Difference Percentage\n",
       "f1          0.045029   4.502851\n",
       "precision   0.085165   8.516484\n",
       "recall      0.010187   1.018676"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_metrics = pd.DataFrame(fair_metrics_sex.difference(method='between_groups'), columns=['Difference'])\n",
    "diff_metrics['Percentage'] = diff_metrics['Difference']*100\n",
    "diff_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "serious-consequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fairness metrics\n",
    "fair_metrics_race = MetricFrame({'f1': f1_score, 'precision': precision_score, 'recall': recall_score},\n",
    "                          y_test, y_pred_mitigated, sensitive_features=X_test_ori['what is your race?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "hourly-classic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f1            0.87013\n",
       "precision    0.887417\n",
       "recall       0.853503\n",
       "dtype: object"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display overall metrics\n",
    "fair_metrics_race.overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "occasional-maria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>what is your race?</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Asian</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black or African American</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I prefer not to answer</th>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.735294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>More than one of the above</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>0.908297</td>\n",
       "      <td>0.920354</td>\n",
       "      <td>0.896552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  f1 precision    recall\n",
       "what is your race?                                      \n",
       "Asian                       0.666667  0.666667  0.666667\n",
       "Black or African American        1.0       1.0       1.0\n",
       "I prefer not to answer      0.757576   0.78125  0.735294\n",
       "More than one of the above       0.8       1.0  0.666667\n",
       "White                       0.908297  0.920354  0.896552"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display metrcis by group\n",
    "fair_metrics_race.by_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "recreational-advertiser",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Difference</th>\n",
       "      <th>Percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Difference Percentage\n",
       "f1          0.333333  33.333333\n",
       "precision   0.333333  33.333333\n",
       "recall      0.333333  33.333333"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_metrics = pd.DataFrame(fair_metrics_race.difference(method='between_groups'), columns=['Difference'])\n",
    "diff_metrics['Percentage'] = diff_metrics['Difference']*100\n",
    "diff_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-heather",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
